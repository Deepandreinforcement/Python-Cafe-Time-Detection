{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058f5087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kütüphaneleri yüklüyoruz.\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a56f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Burada kullanacağımız modeli seçiyoruz.\n",
    "model= YOLO(\"yolov8l.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1272361",
   "metadata": {},
   "source": [
    "Burada temel mantık şu şekilde. Her bir masa için bir bölge tanımlıyoruz. Bu bölgeler masalarda bulunan kişileri kapsayacak genişlikte olmalı. Bunun için kişilerin orta noktasını kullanıyoruz. Ardından o bölgede bulunan kişilere bakıyoruz.\n",
    "\n",
    "Burada zamanı ölçmek için şöyle bir mantık kullandım. Kişinin ilk o bölgede bulunduğu anın kaçıncı frame olduğunu kaydedip bunu güncel frame'den çıkardım. Böylece arada kaç frame fark olduğunu buldum. Sonrasında bu farkı bir frame'nin süresi ile çarptım. Bir frame'nin ne kadar sürdüğünü ise videonun FPS'sinden hesapladım. Örneğin bir video 25 FPS ise bu durumda bir frame 1/25 yani 0.04 saniye uzunluğundadır.\n",
    "\n",
    "Normalde kişinin ilk bulunduğu anı time.time ile alıp güncel andan çıkarabiliriz. Fakat burada şöyle bir sorun var. Kodun frame'i işleme süresi videonun normal frame süresi ile uyumlu olmayabilir. Örneğin kodun buradaki işlemleri her bir frame için yapma süresi 0.1 saniye olursa bu durumda koddaki FPS 10 olacaktır. Bu durumda videodaki gerçek süre yanlış hesaplanmış olur. Bundan dolayı bu benim yaptığım şekilde hesaplamak daha sağlıklı sonuöçlar verecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5a6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.97002997002997 frames per second\n"
     ]
    }
   ],
   "source": [
    "# Kullanılacak videoyu tanımladık.\n",
    "kamera= cv2.VideoCapture('video.mp4')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "\n",
    "# Her bir masa için bölge tanımlıyoruz\n",
    "region1=np.array([(100,200),(1100,200),(1100,700),(100,700)])\n",
    "region1 = region1.reshape((-1,1,2))\n",
    "\n",
    "# Videonun gerçek FPS'sini buluyoruz.\n",
    "fps = kamera.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"{fps} frames per second\")\n",
    "\n",
    "# Frame'lerin indisini bununla tutuyoruz. Yani kaçıncı frame olduğunu\n",
    "count=0\n",
    "\n",
    "# Masalardaki kişilerin kendilerine özel olan id'leri ve ilk defa kaçıncı frame'da o masada oldukları bigisini burada tutuyoruz\n",
    "first_entering = {}\n",
    "while True:\n",
    "\n",
    "   \n",
    "   \n",
    "    ret,kare=kamera.read()\n",
    "    \n",
    "    # Her bir frame'da bunu arttırıyoruz\n",
    "    count+=1\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    imgs=cv2.cvtColor(kare,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resmi modele veriyoruz. Tracking yapılacağı için track modunda verdik\n",
    "    results = model.track(imgs, persist=True, verbose=False)\n",
    "    labels=results[0].names\n",
    "    \n",
    "    # Resimde kaç tane nesne varsa o kadar döner bu döngü. \n",
    "    # Yani her bir döngüde bir nesneye bakıyoruz.\n",
    "    # Burada gerekli olan bilgileri alıp uygun formata çeviriyoruz.\n",
    "    for i in range(len(results[0].boxes)):\n",
    "        \n",
    "        # Tespit edilen nesnelerin konumları.\n",
    "        # x1 ve y1 sol üst köşe. x2 ve y2 sağ alt köşe koordinatları.\n",
    "        x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "        \n",
    "        # Tespit edilen nesnelerin score değerleri.\n",
    "        score=results[0].boxes.conf[i]\n",
    "        \n",
    "        # Tespit edilen nesnelerin ait hangi sınıfa ait oldukları\n",
    "        label=results[0].boxes.cls[i]\n",
    "        \n",
    "        # Tespit edilen nesnelerin id'leri \n",
    "        ids=results[0].boxes.id[i]\n",
    "        \n",
    "        # Değerleri uygun bir fomata çevirdik.\n",
    "        x1,y1,x2,y2,score,label,ids=int(x1),int(y1),int(x2),int(y2),float(score),int(label),int(ids)\n",
    "        \n",
    "        # Burada sınıf bilgisi sayılar ile tutuluyor bunlara karşılık gelen adları atadık\n",
    "        name=labels[label]\n",
    "        \n",
    "        #  burada 0.5' lik bir threshold uyguladık. Tespit edilme değeri daha küçükse değerlendirmeye almıyoruz\n",
    "        if score<0.5:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        # Sadece insan tespiti yapması için\n",
    "        if name!='person':\n",
    "            continue\n",
    "            \n",
    "        # Nesnelerin ortasının konumu buluyoruz.\n",
    "        cx=int(x1/2+x2/2)\n",
    "        cy=int(y1/2+y2/2)\n",
    "        \n",
    "        \n",
    "        # Nesnenin yani kişinin orta noktasının masanın olduğu  bölgeye girip girmedğine bakıyoruz\n",
    "        # Buradaki işlemleri her masa için tekrar ediyoruz.\n",
    "        inside_region1=cv2.pointPolygonTest(region1,(cx,cy),False)\n",
    "        \n",
    "        # Eğer kişinin orta noktası masanın olduğu bölgeye girmişse if bloğunun içine girilir.\n",
    "        if inside_region1>0:\n",
    "\n",
    "\n",
    "            # Burada kişin id'si listenin içinde var mı diye bakıyoruz. \n",
    "            # Eğer varsa bu durumda kişi bir süredir masanın içinde demektir.\n",
    "\n",
    "\n",
    "            if ids  in first_entering:\n",
    "                \n",
    "                # Burada kişinin ilk defa olduğu anı güncel frame değerinden çıkarıyoruz.\n",
    "                fark=count-first_entering[ids]\n",
    "                \n",
    "                # Bu farkı bir frame süresi ile çarpıyoruz. \n",
    "                zaman=fark*(1/fps)\n",
    "                zaman=int(zaman)\n",
    "                # Bunu uygun formatta ekranda gösteriyoruz.\n",
    "                text_zaman='Sure: '+str(zaman)+' sn'\n",
    "                cv2.putText(kare,text_zaman ,(x1, y1-10), font, 0.7, (255,255,255), 2)\n",
    "            \n",
    "            #Yukarıdaki if bloğunun içine girmezse bu durumda kişi ilk defa masanın içinde bulunuyor demektir\n",
    "            else:\n",
    "                # Burada kişinin id'si ile beraber hangi an olduğunu kaydediyoruz\n",
    "                first_entering[ids]=count\n",
    "    \n",
    "    # İsterseniz aşağıdaki satırı yorumdan kaldırıp bölgeleri ekranda gösterebilirsiniz\n",
    "    #cv2.polylines(kare,[region1],True,(0,0,255),2)\n",
    "    cv2.imshow(\"kamera\",kare)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "kamera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
